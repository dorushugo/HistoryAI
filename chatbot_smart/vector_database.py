import os
import faiss
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer

# ğŸ”¹ Charger les donnÃ©es
df = pd.read_csv("guerres_details_full_clean.csv")

# ğŸ”¹ Remplacer NaN par une valeur par dÃ©faut
df.fillna("", inplace=True)

# ğŸ”¹ GÃ©nÃ©rer le texte structurÃ© pour chaque guerre
df["Texte_IndexÃ©"] = df.apply(lambda row: f"""
ğŸ›ï¸ Nom : {row['Nom']}
ğŸ“… Date : {row['Date']}
ğŸ“ Lieu : {row['Lieu']}
âš”ï¸ Issue : {row['Issue']}
ğŸ“œ RÃ©sumÃ© : {row['RÃ©sumÃ©']}
ğŸ” Sections : {row['Sections']}
ğŸ“– Extrait : {row['Contenu_complet'][:500]}...
""", axis=1)

# ğŸ”¹ Initialiser le modÃ¨le d'embedding en franÃ§ais
# model = SentenceTransformer("dangvantuan/sentence-camembert-large")
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")


# ğŸ”¹ GÃ©nÃ©rer les embeddings
descriptions = df["Texte_IndexÃ©"].tolist()
embeddings = model.encode(descriptions)

# ğŸ”¹ CrÃ©er l'index FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# ğŸ”¹ Sauvegarder l'index FAISS
if not os.path.exists("data"):
    os.makedirs("data")

faiss.write_index(index, "data/guerres_faiss.index")

# ğŸ”¹ Sauvegarder le mapping des guerres
df["ID"] = range(len(df))
df_mapping = df[["ID", "Nom", "Date", "Lieu", "Issue", "RÃ©sumÃ©", "Conclusion", "Sections", "URL"]]
df_mapping.to_pickle("data/guerres_mapping.pkl")

print("âœ… Base vectorielle mise Ã  jour avec succÃ¨s !")