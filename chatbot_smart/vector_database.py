import os
import faiss
import pandas as pd
import re
import spacy
import unicodedata
import numpy as np
from sentence_transformers import SentenceTransformer

# ğŸ”¥ Chargement du modÃ¨le NLP franÃ§ais pour la lemmatisation
nlp = spacy.load("fr_core_news_lg") # modÃ¨le sm plus petit si besoin

# ğŸ”¹ Charger les donnÃ©es
df = pd.read_csv("guerres_details_full_clean.csv")

df.fillna("", inplace=True)
# ğŸ”¹ Nettoyage des textes
def clean_text(text):
    if pd.isna(text):
        return ""

    # Convertir en minuscules
    text = text.lower()

     # Supprimer les accents
    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')
    
   # Remplacer les caractÃ¨res spÃ©ciaux sauf les nombres et les annÃ©es
    text = re.sub(r"[^a-zA-Z0-9\s-]", "", text)
    
    # Supprimer les espaces en trop
    text = re.sub(r"\s+", " ", text).strip()
    
    return text

# ğŸ”¹ GÃ©nÃ©rer le texte structurÃ© pour chaque guerre
df["Texte_IndexÃ©"] = df.apply(lambda row: f"""
ğŸ›ï¸ Nom : {row['Nom']}
ğŸ“… Date : {row['Date']}
ğŸ“ Lieu : {row['Lieu']}
âš”ï¸ Issue : {row['Issue']}
ğŸ“œ RÃ©sumÃ© : {row['RÃ©sumÃ©']}
ğŸ” Sections : {row['Sections']}
ğŸ“– Extrait : {row['Contenu_complet'][:500]}...
""", axis=1)

# df["Texte_IndexÃ©"] = df["Texte_IndexÃ©"].apply(clean_text)

# ğŸ”¹ Stopwords et Lemmatisation
stopwords_fr = set(nlp.Defaults.stop_words)

def preprocess_text(text):
    doc = nlp(text)
    tokens = [token.lemma_ for token in doc if token.text not in stopwords_fr and not token.is_punct]
    return " ".join(tokens)

# df["Texte_IndexÃ©"] = df["Texte_IndexÃ©"].apply(preprocess_text)

# ğŸ”¹ VÃ©rifier le contenu final
# print(df[["Texte_IndexÃ©"]].head())

# # ğŸ”¹ Initialiser le modÃ¨le d'embedding en franÃ§ais
# model = SentenceTransformer("dangvantuan/sentence-camembert-base")
# model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
model = SentenceTransformer('Lajavaness/bilingual-document-embedding', trust_remote_code=True)

# ğŸ”¹ GÃ©nÃ©rer les embeddings
descriptions = df["Texte_IndexÃ©"].tolist()
embeddings = model.encode(descriptions)
print(f"âœ… Dimension des embeddings FAISS : {embeddings.shape[1]}")


# ğŸ”¹ CrÃ©er l'index FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# ğŸ”¹ Sauvegarder l'index FAISS
if not os.path.exists("data"):
    os.makedirs("data")

faiss.write_index(index, "data/guerres_faiss_NLP2.index")
# ğŸ”¹ Sauvegarder le mapping des guerres
df["ID"] = range(len(df))
df_mapping = df[["ID", "Nom", "Date", "Lieu", "Issue", "RÃ©sumÃ©", "Conclusion", "Sections", "URL"]]
df_mapping.to_pickle("data/guerres_mapping_NLP.pkl")

print("âœ… Base vectorielle mise Ã  jour avec succÃ¨s !")