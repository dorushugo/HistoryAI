import subprocess
import pandas as pd
from scrappers.url_detail import get_infos_guerre  # Importation de la fonction pour rÃ©cupÃ©rer les infos dÃ©taillÃ©es
import faiss
import json
import numpy as np
from sentence_transformers import SentenceTransformer

def main():
    print("DÃ©marrage du script principal")
    # Ton code principal ici

    # Ã‰tape 1: RÃ©cupÃ©rer les URLs des guerres via le premier scraper
    print("ğŸ“¡ RÃ©cupÃ©ration des URLs des guerres...")
    subprocess.run(["python3", "scrappers/scrapper_url.py"])

    # Ã‰tape 2: Charger les URLs rÃ©cupÃ©rÃ©es dans le fichier CSV
    guerres_df = pd.read_csv("details_guerres.csv")

    guerres_details = []

    # Ã‰tape 3: RÃ©cupÃ©rer les informations dÃ©taillÃ©es pour chaque guerre
    print("ğŸ“ RÃ©cupÃ©ration des informations dÃ©taillÃ©es...")
    for index, row in guerres_df.iterrows():
        print(f"ğŸ“ RÃ©cupÃ©ration des informations pour {row['Nom']}...")
        infos_guerre = get_infos_guerre(row["URL"])
        if infos_guerre:
            guerres_details.append(infos_guerre)

    # Ã‰tape 4: Sauvegarder les informations dÃ©taillÃ©es dans un CSV
    details_df = pd.DataFrame(guerres_details)
    details_df.to_csv("guerres_details_completes.csv", index=False, encoding="utf-8")
    print("âœ… DonnÃ©es dÃ©taillÃ©es enregistrÃ©es dans 'guerres_details_completes.csv'.")
    return details_df

if __name__ == "__main__":
    df = main()

    # ğŸ”¥ CHOISIR UN MODÃˆLE MULTILINGUE POUR LE FRANÃ‡AIS
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # VÃ©rification des colonnes attendues
    colonnes_attendues = ["Nom", "URL", "Date", "Lieu", "Issue", "RÃ©sumÃ©", "Conclusion", "Sections"]
    for col in colonnes_attendues:
        if col not in df.columns:
            raise ValueError(f"âš ï¸ La colonne '{col}' est absente du DataFrame ! VÃ©rifie tes donnÃ©es.")

    # Remplir les valeurs manquantes pour Ã©viter les erreurs
    df.fillna("Non renseignÃ©", inplace=True)

    # # AMZELIORATION A TESTER POUR LE FUTUR, EN AJOUTANT UN CHAMP POUR FAIRE L'EMBEDDING DES 3 CHAMPS AU LIEU DE QUE RESUMÃ‰
    # # ğŸ”¹ GÃ©nÃ©rer des descriptions enrichies (Nom + Date + RÃ©sumÃ©)
    # df["Texte_IndexÃ©"] = df["Nom"] + " " + df["Date"] + " " + df["RÃ©sumÃ©"]

    # # ğŸ”¹ GÃ©nÃ©rer des embeddings pour ce texte enrichi
    # descriptions = df["Texte_IndexÃ©"].tolist()
    # embeddings = model.encode(descriptions)

    # ğŸ”¹ GÃ©nÃ©rer des embeddings pour la colonne `RÃ©sumÃ©`
    descriptions = df["RÃ©sumÃ©"].tolist()
    embeddings = model.encode(descriptions)

    # ğŸ”¹ CrÃ©er l'index FAISS
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings))  # Ajouter les vecteurs FAISS

    # ğŸ”¹ Sauvegarder l'index FAISS
    faiss.write_index(index, "data/events_faiss.index")

    # ğŸ”¹ Ajouter un ID unique Ã  chaque Ã©vÃ©nement et stocker les donnÃ©es utiles
    df["ID"] = range(len(df))
    df_mapping = df[["ID", "Nom", "Date", "Lieu", "Issue", "RÃ©sumÃ©", "Conclusion", "Sections", "URL"]]
    df_mapping.to_pickle("data/events_mapping.pkl")  # Stocker en Pickle pour un accÃ¨s rapide

    print("âœ… Base vectorielle crÃ©Ã©e avec succÃ¨s Ã  partir du DataFrame !")