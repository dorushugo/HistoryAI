import os
import faiss
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
import pickle

# ğŸ”¥ ModÃ¨le d'embeddings en franÃ§ais
# model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")

# ğŸ”¹ Charger les donnÃ©es Ã  partir d'un DataFrame pandas (ex: rÃ©cupÃ©rÃ© d'un CSV)
df = pd.read_csv("guerres_details_completes.csv")

# #AMELIORATION 
# # ğŸ”¹ GÃ©nÃ©rer des descriptions enrichies (Nom + Date + RÃ©sumÃ©)
# df["Texte_IndexÃ©"] = df["Nom"] + " " + df["Date"] + " " + df["RÃ©sumÃ©"]

# ğŸ”¹ VÃ©rifier que les colonnes attendues existent
colonnes_attendues = ["Nom", "URL", "Date", "Lieu", "Issue", "RÃ©sumÃ©", "Conclusion", "Sections"]
for col in colonnes_attendues:
    if col not in df.columns:
        raise ValueError(f"âš ï¸ La colonne '{col}' est absente du DataFrame ! VÃ©rifie tes donnÃ©es.")


# ğŸ”¹ Remplir les valeurs manquantes pour Ã©viter les erreurs
df.fillna("", inplace=True)

df["Texte_IndexÃ©"] = (
    df["Nom"] + " " + df["Date"] + " " + df["Lieu"] + " " +
    df["RÃ©sumÃ©"] + " " + df["Conclusion"]
)

# ğŸ”¹ GÃ©nÃ©rer des embeddings pour la colonne `Texte_IndexÃ©`
descriptions = df["Texte_IndexÃ©"].tolist()
embeddings = model.encode(descriptions)

# ğŸ”¹ GÃ©nÃ©rer des embeddings pour ce texte enrichi
# descriptions = df["Texte_IndexÃ©"].tolist()
# embeddings = model.encode(descriptions)

# ğŸ”¹ CrÃ©er l'index FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# ğŸ”¹ VÃ©rifier que le dossier "data/" existe avant d'enregistrer FAISS
if not os.path.exists("data"):
    os.makedirs("data")

# ğŸ”¹ Sauvegarder l'index FAISS
faiss.write_index(index, "data/events_faiss.index")

# ğŸ”¹ Ajouter un ID unique Ã  chaque Ã©vÃ©nement et stocker les donnÃ©es utiles
df["ID"] = range(len(df))
df_mapping = df[["ID", "Nom", "Date", "Lieu", "Issue", "RÃ©sumÃ©", "Conclusion", "Sections", "URL"]]
df_mapping.to_pickle("data/events_mapping.pkl")  # Stocker en Pickle pour un accÃ¨s rapide

# ğŸ”¹ Ajouter une recherche hybride avec TF-IDF
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df["Texte_IndexÃ©"])

# ğŸ”¹ Sauvegarder TF-IDF
pickle.dump(vectorizer, open("data/tfidf_vectorizer.pkl", "wb"))
pickle.dump(tfidf_matrix, open("data/tfidf_matrix.pkl", "wb"))

print("âœ… Base vectorielle FAISS et TF-IDF crÃ©Ã©es avec succÃ¨s !")